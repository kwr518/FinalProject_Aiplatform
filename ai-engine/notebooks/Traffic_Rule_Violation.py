#!/usr/bin/env python
# coding: utf-8

# ## LRCN ë¶„ë¥˜

# # Modules

# In[1]:

import os
import cv2
import math
import random
import datetime
import numpy as np
import datetime as dt
import tensorflow as tf
from collections import deque
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import Sequence
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import plot_model


# In[ ]:


# seed 27ë²ˆ ê³ ì • 
seed_constant = 27
np.random.seed(seed_constant)
random.seed(seed_constant)
tf.random.set_seed(seed_constant)


# In[ ]:


# signal: ì‹ í˜¸ë“± ìƒíƒœ ì¸ì‹, middleLine: ì¤‘ì•™ì„  ì¹¨ë²”, whiteLine: ì°¨ì„  ìœ„ë°˜
all_classes = ['Signal', 'middleLine', 'whiteLine']
categories = ['ì‹ í˜¸ìœ„ë°˜','ì¤‘ì•™ì„ ì¹¨ë²”','ì§„ë¡œë³€ê²½ìœ„ë°˜']    # ëª¨ë¸ì´ ë¶„ë¥˜í•  í•­ëª©
IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64                 # ê°€ë¡œ x ì„¸ë¡œ 64px ë¦¬ì‚¬ì´ì§•
SEQUENCE_LENGTH = 25                                # í•˜ë‚˜ì˜ ì˜ìƒ ìƒ˜í”Œë‹¹ í”„ë ˆì„ ê°œìˆ˜


# In[ ]:


# path ê²½ë¡œì— í´ë” ì—†ì„ ê²½ìš° ë””ë ‰í† ë¦¬ ìƒì„±
def createDirectory(path):
    if not os.path.exists(path):
        os.mkdir(path)

# í´ë” ë‚´ ì§€ì •ëœ í”„ë ˆì„ë“¤ì„ ëª¨ì•„ ëª¨ë¸ ì…ë ¥ìš© ì‹œí€¸ìŠ¤ ë°ì´í„°ë¡œ ë³€í™˜
def frame_extraction(folder_path):
    frame_list = []
    
    # [Point 1] íŒŒì¼ëª… ì •ë ¬ (í•„ìˆ˜!)
    try:
        file_names = sorted(os.listdir(folder_path))
    except FileNotFoundError:
        print(f"âŒ ê²½ë¡œ ì—†ìŒ: {folder_path}")
        return []
    
    file_paths = [os.path.join(folder_path, i) for i in file_names]
    
    for file in file_paths:
        if not file.lower().endswith(('.jpg', '.jpeg', '.png')):    # ì´ë¯¸ì§€ í™•ì¥ì í•„í„°ë§
            continue
            
        try:
            img_array = np.fromfile(file, np.uint8)
            frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            
            # [Point 2] ì•ˆì „ì¥ì¹˜
            if frame is None: continue
            
            resized = cv2.resize(frame, (IMAGE_HEIGHT , IMAGE_WIDTH))
            normalized = resized / 255.0
            frame_list.append(normalized)
            
            if len(frame_list) == SEQUENCE_LENGTH:
                break
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¡œë“œ ì—ëŸ¬: {e}")

    # [Point 3] íŒ¨ë”© (í”„ë ˆì„ ë¶€ì¡± ì‹œ ì±„ì›€)
    if 0 < len(frame_list) < SEQUENCE_LENGTH:
        while len(frame_list) < SEQUENCE_LENGTH:
            frame_list.append(frame_list[len(frame_list) % len(frame_list)])
            
    return frame_list


# In[ ]:
def get_data(paths, labels):    
    for folder_path, label_index in zip(paths,labels):  # í´ë” ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ì™€ ì •ë‹µ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ìŒìœ¼ë¡œ ë¬¶ê¸°
        feature = frame_extraction(folder_path) # frame_extraction í˜¸ì¶œ í›„ 25ì¥ ì •ê·œí™” í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
        feature = np.array(feature) # ë¦¬ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ì•„ ë„˜íŒŒì´ ë°°ì—´ë¡œ ìˆ˜ì •

        label = np.array([label_index]) # (í”¼ì²˜, ë¼ë²¨) ìŒì„ ëª¨ë¸ í•™ìŠµ ë£¨í”„ì— ì „ë‹¬
        yield (feature, label)      # yield ì‚¬ìš© ì‹œ í˜„ì¬ ì²˜ë¦¬ì¤‘ì¸ ì˜ìƒ í•œê°œë§Œ ë©”ëª¨ë¦¬ì— ìœ ì§€í•˜ì—¬ ì„±ëŠ¥ ë°©ì–´


# In[ ]:


def create_paths(data_type):
    labels = []
    paths = []
    for label in categories:
        print("ì§„í–‰ì¤‘:", label)
        
        path = f"/mnt/traffic/êµí†µë°ì´í„°/{data_type}ì´ë¯¸ì§€ë°ì´í„°/{label}"
        for root, directories, files in os.walk(path):  # í˜„íƒìƒ‰ ì¤‘ì¸ ê²½ë¡œ ë‚´ í•˜ìœ„ í´ë”ê¹Œì§€ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
            for file in files:  
                if file.split('.')[-1] =='jpg' or file.split('.')[-1]=='jpeg':  # jpg, jpeg ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
                    
                    if root not in paths:   # í´ë” ê²½ë¡œê°€ ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì— ë“±ë¡ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš° ë°ì´í„° ê²½ë¡œ ì¶”ê°€
                        paths.append(root)  
                        labels.append(categories.index(label))  # ìœ„ë°˜ í•­ëª© ìˆ«ìë¡œ ë³€í™˜í•´ ì •ë‹µ ë¦¬ìŠ¤íŠ¸ì— ë„£ê¸°
    print('=========================')
    return paths, labels


# In[ ]:

class Dataloader(Sequence):
    def __init__(self, x_set, y_set, batch_size, shuffle=False):
        self.x, self.y = x_set, y_set   # ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ë° ì •ë‹µ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ì €ì¥
        self.batch_size = batch_size    # í•œë²ˆì— í•™ìŠµí•  ë°ì´í„° ì–‘
        self.shuffle=shuffle            # í•œ ì—í­ì´ ëë‚ ë•Œë§ˆë‹¤ ë°ì´í„° ìˆœì„œ ì„ê¸° 
        self.on_epoch_end()             # ì´ˆê¸°í™” ì‹œì ì— í•œ ë²ˆ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ì¸ë±ìŠ¤ ìƒì„±

    # ì „ì²´ ê°œìˆ˜ë¥¼ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¡œ
    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size) # ì†Œìˆ˜ì ì¼ ê²½ìš° ì˜¬ë¦¼í•˜ì—¬ ìíˆ¬ë¦¬ ë°ì´í„° í¬í•¨

	# batch ë‹¨ìœ„ë¡œ ì§ì ‘ ë¬¶ì–´ì¤˜ì•¼ í•¨
    def __getitem__(self, idx):
				# samplerì˜ ì—­í• (indexë¥¼ batch_sizeë§Œí¼ samplingí•´ì¤Œ)
        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]

        batch_x = [frame_extraction(self.x[i]) for i in indices]    # ì¶”ì¶œëœ ì¸ë±ìŠ¤ë¥¼ í˜¸ì¶œí•´ ì´ë¯¸ì§€ë¥¼ ì½ì–´ì™€ 25ì¥ì˜ ì‹œí€¸ìŠ¤ ë°ì´í„°ë¡œ ë³€í™˜
        batch_y = [self.y[i] for i in indices]  # í•´ë‹¹ ì˜ìƒë“¤ì˜ ì •ë‹µ ë¼ë²¨ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ìœ¼ê¸°
    
        # 0,1,2 ë³¸ë¥˜ ëª¨ë¸ ì´í•´ë¥¼ ìœ„í•œ ì›í•« ì¸ì½”ë”©ìœ¼ë¡œ ë³€ê²½(ì‹ í˜¸ìœ„ë°˜, ì¤‘ì•™ì„ ì¹¨ë²”, ì§„ë¡œë³€ê²½ìœ„ë°˜)
        return np.asarray(batch_x), to_categorical(np.array(batch_y), num_classes=3)    

    # epochì´ ëë‚ ë•Œë§ˆë‹¤ ì‹¤í–‰
    def on_epoch_end(self):
        self.indices = np.arange(len(self.x))   # ë°ì´í„° ìˆœì„œëŒ€ë¡œ ì¸ë±ìŠ¤ ë²ˆí˜¸ ë‹¤ì‹œ ìƒì„±
        if self.shuffle == True:    # ì¸ë±ìŠ¤ ìˆœì„œ ë¬´ì‘ìœ„ë¡œ ì„ì–´ ë°ì´í„° ìˆœì„œë¥¼ ì™¸ìš°ëŠ” ê³¼ì í•© ë°©ì§€
            np.random.shuffle(self.indices)


# In[9]:

train_paths, train_labels = create_paths('')    # í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„
val_paths, val_labels = create_paths('val_')    # í´ë” ê²½ë¡œ íƒìƒ‰ í›„ í•™ìŠµ ì¤‘ ì„±ëŠ¥ì„ ì²´í¬í•  ê²€ì¦ ë°ì´í„° ì¤€ë¹„


# In[ ]:

test_paths, test_labels = create_paths('test_') # í´ë” ê²½ë¡œ íƒìƒ‰ ë° ì£„ì¢… ì„±ëŠ¥ í‰ê°€ìš© ë°ì´í„° ì¤€ë¹„

# In[11]:

# Dataloader í•¨ìˆ˜ì— í˜¸ì¶œ
train_dataset = Dataloader(train_paths, train_labels, 24, shuffle=True)
val_dataset =  Dataloader(val_paths, val_labels, 24)
test_dataset =  Dataloader(test_paths, test_labels, 24)


# In[12]:


# LRCN : ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” CNNê³¼ ì‹œê°„ íë¦„ì„ ë¶„ì„í•˜ëŠ” LSTMì˜ ê²°í•©í˜•íƒœ
categories = ['ì‹ í˜¸ìœ„ë°˜','ì¤‘ì•™ì„ ì¹¨ë²”','ì§„ë¡œë³€ê²½ìœ„ë°˜']
def create_LRCN_model():
    model = Sequential()

    # TimeDistributed : ì…ë ¥ë°›ì€ 25ê°œì˜ í”„ë ˆì„ ê°ê°ì— ë™ì¼í•œ CNN ì—°ì‚° ì ìš©
    # Conv2D : 16ê°œì˜ í•„í„°ë¥¼ ì‚¬ìš©í•´ ê¸°ì´ˆì ì¸ íŠ¹ì§•(ì„ , ë©´ ë“±)ì„ ì°¾ê¸°
    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu'),
                              input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))
    
    model.add(TimeDistributed(MaxPooling2D((4, 4)))) # MaxPooling(4, 4) : ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 1/4ë¡œ ì¤„ì—¬ ì¤‘ìš”í•œ ì •ë³´ë§Œ ë‚¨ê¸°ê¸°
    model.add(TimeDistributed(Dropout(0.25))) # Dropout(0.25) : í•™ìŠµ ì‹œ ë…¸ë“œì˜ 25% ë¬´ì‘ìœ„ë¡œ êº¼ì„œ ê³¼ì í•© ë°©ì§€
    
    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))
    model.add(TimeDistributed(MaxPooling2D((4, 4))))
    model.add(TimeDistributed(Dropout(0.25)))
    
    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))
    model.add(TimeDistributed(MaxPooling2D((2, 2))))
    model.add(TimeDistributed(Dropout(0.25)))
    
    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))
    model.add(TimeDistributed(MaxPooling2D((2, 2))))
    #model.add(TimeDistributed(Dropout(0.25)))
                                      
    model.add(TimeDistributed(Flatten()))   # CNNì„ í†µí•´ ë‚˜ì˜¨ 2ì°¨ì› íŠ¹ì§• ë§µì„ 1ì°¨ì› ë²¡í„°ë¡œ í¼ì¹˜ê¸°               
    model.add(LSTM(32)) # 25ê°œ í”„ë ˆì„ì˜ íë¦„ì„ ê¸°ì–µí•˜ë©° ë¶„ì„(ì°¨ëŸ‰ ê¶¤ì  ì¤‘ì•™ì„  ì¹¨ë²”, ì‹ í˜¸ ìœ„ë°˜ ë“± ë™ì  ì›€ì§ì„ íŒë‹¨)
    model.add(Dense(len(categories), activation = 'softmax')) # ìµœì¢… ì¶œë ¥ ë…¸ë“œ 3ê°œ ë°, ê° ìœ„ë°˜ í•­ëª©ì— í•´ë‹¹í•  í™•ë¥ ì€ 0 ~ 1ì‚¬ì´ë¡œ ì¶œë ¥í•˜ë©° ì„¸ í•­ëª©ì˜ í•©ì€ 1

    
    model.summary()     # ëª¨ë¸ ìš”ì•½ ë””ìŠ¤í”Œë ˆì´
    return model        # LRCN ëª¨ë¸ ë¦¬í„´
LRCN_model = create_LRCN_model()


# In[17]:


dir_name = 'snap_shot'

# í•™ìŠµ ê³¼ì • ê¸°ë¡ ë° ì‹œê°í™”(TensorBoard)
def make_Tensorboard_dir(dir_name): # ì‹¤í–‰ ì‹œê°„ ë³„ í´ë” ì œì‘
    root = os.path.join(os.curdir, dir_name)    # snap_shot ì´ë¦„ì˜ ë©”ì¸ í´ë” ê²½ë¡œ ì§€ì •
    sub_dir = datetime.datetime.now().strftime("%Y%m%d-%H%M%S") # í•˜ìœ„ í´ë”ë¡œ 'YMD-HMS'í˜•íƒœë¡œ í´ë” ëª… ìƒì„±
    
    # í´ë” ì—†ì„ ê²½ìš° ì‹¤ì œ ìƒì„±
    if not os.path.exists(root):    
        os.mkdir(root)
    if not os.path.exists(os.path.join(root, sub_dir)):
        os.mkdir(os.path.join(root, sub_dir))
    return os.path.join(root, sub_dir)

# í…ì„œë³´ë“œ ì½œë°± ì„¤ì •
TB_log_dir = make_Tensorboard_dir(dir_name) # ìœ„ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ ì‹¤ì œ ë¡œê·¸ê°€ ì €ì¥ë  ìµœì¢… ê²½ë¡œ ì„¤ì •

# model.fitì˜ callbacks ë¦¬ìŠ¤íŠ¸ì— ë„£ìœ¼ë©´ í•™ìŠµ ê³¼ì • ì¤‘ ë°œìƒí•˜ëŠ” ëª¨ë“  ì§€í‘œ í•´ë‹¹ íŒŒì¼ì— ê¸°ë¡ë¨
TensorB = tf.keras.callbacks.TensorBoard(log_dir = TB_log_dir)  


# In[21]:

# ì¡°ê¸° ì¢…ë£Œ ì„¤ì •(EarlyStopping)
early_stopping_callback = EarlyStopping(monitor = 'val_loss',  # ê²€ì¦ ë°ì´í„° ì†ì‹¤ê°’ ê´€ì°°
                                        patience = 15,  # 15 Epoch ë™ì•ˆ í–¥ìƒ ì—†ì„ ê²½ìš° í•™ìŠµ ì¤‘ë‹¨
                                        mode = 'min',   # ì§€í‘œê°€ ì¤„ì–´ë“œëŠ” ê²ƒì´ ë©ˆì¶œ ë•Œ ì¤‘ë‹¨
                                        restore_best_weights = True)    # í•™ìŠµ ì¤‘ë‹¨ ì‹œ Lossê°€ ê°€ì¥ ë‚®ì•˜ë˜ ì‹œì ì˜ ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ ì„ íƒ
 

LRCN_model.compile(loss = 'categorical_crossentropy', # ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì— ì‚¬ìš©í•˜ëŠ” í‘œì¤€ ì†ì‹¤ í•¨ìˆ˜
                   optimizer = 'Adam', # ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” í•™ìŠµ ìµœì í™” ì•Œê³ ë¦¬ì¦˜
                   metrics = ["accuracy"])  # í„°ë¯¸ë„ì— ì •í™•ë„ ì¶œë ¥
 
# Start training the model.

with tf.Graph().as_default():
    gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)    # í•™ìŠµì— í•„ìš”í•œ ë§Œí¼ë§Œ ë©”ëª¨ë¦¬ í• ë‹¹
with tf.device("/device:GPU:1"):    # ì»´í“¨í„°ì— ì„¤ì¹˜ëœ GPU ì¸ë±ìŠ¤ ì„ íƒí•˜ì—¬ ìˆ˜í–‰
    LRCN_model_training_history2 = LRCN_model.fit(train_dataset, # Dataloaderë¡œ ë§Œë“  ë°ì´í„° ê³µê¸‰
                                                  epochs = 500,  
                                                  workers=4 ,    # CPU 4EA ë³‘ë ¬ ì²˜ë¦¬
                                                  shuffle = True,   # ì…”í”Œ
                                                  validation_data= val_dataset, # í•™ìŠµ ì¤‘ê°„ë§ˆë‹¤ ê²€ì¦ ë°ì´í„°ë¥¼ ë„£ì–´ ì²˜ìŒ ë³´ëŠ” ì˜ìƒë„ ì˜ë§íˆëŠ”ì§€ ì„±ëŠ¥ ì²´í¬
                                                  callbacks = [early_stopping_callback, TensorB])   # ê²€ì¦ ì†ì‹¤ì´ ì¤„ì–´ë“¤ì§€ ì•Šì€ ê²½ìš° ì¡°ê¸° ì¢…ë£Œ ë° ë¡œê·¸ ì €ì¥


# In[23]:


def plot_metric(model_training_history, # í•™ìŠµ ì¤‘ ê¸°ë¡ëœ loss, accuracy ë°ì´í„°ê°€ ë‹´ê¸´ ê°ì²´
                metric_name_1,  # ê·¸ë˜í”„ì— ì¶œë ¥í•  ë°ì´í„°ì˜ ì´ë¦„
                metric_name_2,   
                plot_name): # ê·¸ë˜í”„ ì œëª©
   
    # hisory.history ë”•ì…”ë„ˆë¦¬ì—ì„œ ì›í•˜ëŠ” ì§€í‘œì˜ ìˆ«ì ë¦¬ìŠ¤íŠ¸ êº¼ë‚´ì˜¤ê¸°
    metric_value_1 = model_training_history.history[metric_name_1]
    metric_value_2 = model_training_history.history[metric_name_2]
    
    # ê·¸ë˜í”„ Xì¶•ìœ¼ë¡œ í•™ìŠµëœ íšŸìˆ˜ë§Œí¼ ìˆœì„œëŒ€ë¡œ ìˆ«ì ìƒì„±
    epochs = range(len(metric_value_1))

    # Blue, Red ì„  ê·¸ë¦¬ê¸°
    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)
    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)

    # Add title to the plot.
    plt.title(str(plot_name))

    # í•™ìŠµìš© ë° ê²€ì¦ìš© ì„¤ëª… í…ìŠ¤íŠ¸ë¡œ êµ¬ë¶„
    plt.legend()


# In[24]:
plot_metric(LRCN_model_training_history2, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')

# In[25]:
plot_metric(LRCN_model_training_history2, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')

# In[26]:
# í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•Šì€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë„£ì–´ ëª¨ë¸ ê²€ì¦ ì§„í–‰
model_evaluation_history = LRCN_model.evaluate(test_dataset)

# ëª¨ë¸ ì €ì¥
# In[29]:
# í‰ê°€ ê²°ê³¼ì—ì„œ ì†ì‹¤ê°’ê³¼ ì •í™•ë„ ì¶”ì¶œ
model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history
 
# datetime ëª¨ë“ˆë¡œ í˜„ì¬ ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ê¹Œì§€ ë¬¸ìì—´ë¡œ ì„¤ì •
date_time_format = '%Y_%m_%d__%H_%M_%S'
current_date_time_dt = dt.datetime.now()
current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)

# íŒŒì¼ ì´ë¦„ì•ˆì— ì €ì¥ ì‹œê°„, ì†ì‹¤ë„, ì •í™•ë„ ì „ë¶€ ë„£ê¸°
model_file_name = f'LRCN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'
save_dir = './lstm_model'
createDirectory(save_dir)

# ëª¨ë¸ êµ¬ì¡°, ê°€ì¤‘ì¹˜, ìµœì í™” ì„¤ì • ì „ë¶€ ë„£ê¸°
LRCN_model.save(os.path.join(save_dir, model_file_name))

# In[2]:

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
LRCN_model = tf.keras.models.load_model('./lstm_model/LRCN_model___Date_Time_2023_03_01__04_35_27___Loss_0.01098685897886753___Accuracy_0.9961240291595459.h5')

# # í´ë”ë³„ f1 score êµ¬í•˜ê¸°

# In[12]:
# í´ë”ë³„ f1_score ì¸¡ì •

# In[46]:


# =========================================================
# 2. í†µí•© í‰ê°€ ë° ë¡œê·¸ ì €ì¥ í•¨ìˆ˜ (In[46] + In[47] ëŒ€ì²´)
# =========================================================
def evaluate_and_log(test_root_folder, save_path='/mnt/traffic/lstm_f1_score.txt'):
    y_true = [] # ì‹¤ì œ ì •ë‹µ
    y_pred = [] # ëª¨ë¸ ì˜ˆì¸¡
    
    print(f"ğŸš€ ë¶„ì„ ì‹œì‘: {test_root_folder}")
    
    # 3ê°€ì§€ í´ë˜ìŠ¤ í´ë”ë¥¼ ëª¨ë‘ ìˆœíšŒ
    for label_idx, label_name in enumerate(categories):
        target_dir = os.path.join(test_root_folder, label_name)
        if not os.path.exists(target_dir):
            print(f"âš ï¸ ê²½ë¡œ ì—†ìŒ íŒ¨ìŠ¤: {target_dir}")
            continue
            
        # í•´ë‹¹ í´ë˜ìŠ¤ í´ë” ë‚´ì˜ ëª¨ë“  ì˜ìƒ í´ë” íƒìƒ‰
        video_folders = []
        for root, dirs, files in os.walk(target_dir):
            if any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in files):
                video_folders.append(root)
        
        print(f"   - [{label_name}] ì˜ìƒ {len(video_folders)}ê°œ ë¶„ì„ ì¤‘...")
        
        for folder in video_folders:
            frames = frame_extraction(folder)
            if not frames: continue
            
            # ëª¨ë¸ ì˜ˆì¸¡
            pred_prob = LRCN_model.predict(np.expand_dims(frames, axis=0), verbose=0)[0]
            pred_idx = np.argmax(pred_prob)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            y_true.append(label_idx)
            y_pred.append(pred_idx)

    print("âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì§‘ê³„ ì¤‘...\n")

    # -----------------------------------------------------
    # 3. ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± ë° íŒŒì¼ ì €ì¥
    # -----------------------------------------------------
    
    # Sklearnì´ ì œê³µí•˜ëŠ” ì •í™•í•œ ì„±ëŠ¥ ë³´ê³ ì„œ (FP, FN ì™„ë²½ ê³„ì‚°ë¨)
    report = classification_report(y_true, y_pred, target_names=categories, digits=4)
    conf_matrix = confusion_matrix(y_true, y_pred)
    
    # í™”ë©´ ì¶œë ¥
    print("="*60)
    print(" [ ìµœì¢… ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ ] ")
    print("="*60)
    print(report)
    print("\n[í˜¼ë™ í–‰ë ¬ (Confusion Matrix)]")
    print(conf_matrix)
    print("="*60)
    
    # íŒŒì¼ ì €ì¥ (ê¸°ì¡´ In[47]ì˜ ëª©ì  ë‹¬ì„±)
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ê²½ë¡œ: {test_root_folder}\n")
        f.write("="*60 + "\n\n")
        f.write(report)
        f.write("\n\n[í˜¼ë™ í–‰ë ¬]\n")
        f.write(str(conf_matrix))
        
    print(f"ğŸ“ ê²°ê³¼ê°€ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")

# =========================================================
# 3. ì‹¤í–‰ (ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”)
# =========================================================

# ê²€ì¦í•˜ê³  ì‹¶ì€ ë°ì´í„°ì…‹ì˜ ìµœìƒìœ„ ê²½ë¡œ (val ë˜ëŠ” test)
# ì˜ˆ: /mnt/traffic/êµí†µë°ì´í„°/lstm_val_ì´ë¯¸ì§€ë°ì´í„°
TEST_DATA_PATH = "/mnt/traffic/êµí†µë°ì´í„°/lstm_val_ì´ë¯¸ì§€ë°ì´í„°"

# í•¨ìˆ˜ ì‹¤í–‰ (ì´ê±° í•œ ì¤„ì´ë©´ ëë‚©ë‹ˆë‹¤!)
evaluate_and_log(TEST_DATA_PATH)

# In[40]:
LRCN_model = tf.keras.models.load_model('./lstm_model/LRCN_model___Date_Time_2023_03_01__04_35_27___Loss_0.01098685897886753___Accuracy_0.9961240291595459.h5')

# In[45]:

def classifier(folder_path):
    categories = ['ì‹ í˜¸ìœ„ë°˜', 'ì¤‘ì•™ì„ ì¹¨ë²”','ì§„ë¡œë³€ê²½ìœ„ë°˜']
    frame_list = frame_extraction(folder_path)
    predicted_labels_probabilities = LRCN_model.predict(np.expand_dims(frame_list, axis=0))[0]
    predicted_label = np.argmax(predicted_labels_probabilities)
    return print(f"íƒì§€ëœ ê²°ê³¼: {categories[predicted_label]}")

def createDirectory(path):
    if not os.path.exists(path):
        os.mkdir(path)

# # ======ì‹ í˜¸ìœ„ë°˜=======

# In[46]:

path = "/mnt/traffic/êµí†µë°ì´í„°/test_ì´ë¯¸ì§€ë°ì´í„°/ì‹ í˜¸ìœ„ë°˜/ì ìƒ‰ì‹ í˜¸ì‹œì§ì§„/20230225_ì ìƒ‰ì‹ í˜¸ì‹œì§ì§„_0000000007/"

path_ = path
fig = plt.figure(figsize=(10,10)) # rows*cols í–‰ë ¬ì˜ ië²ˆì§¸ subplot ìƒì„±
rows = 5
cols = 5
i = 1
 
xlabels = [f"{x}" if x!=0 else 'xlabel' for x in range(26) ]


for filename in sorted(os.listdir(path_))[:25]:
    filename = os.path.join(path_, filename)
    img = cv2.imread(filename)
    
    ax = fig.add_subplot(rows, cols, i)
    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax.set_xlabel(xlabels[i])
    ax.set_xticks([]), ax.set_yticks([])
    i += 1

plt.show()
classifier(path)


# In[58]:
# In[48]:
# In[49]:
# # ======ì¤‘ì•™ì„ ì¹¨ë²”=======

# In[50]:

path = "/mnt/traffic/êµí†µë°ì´í„°/test_ì´ë¯¸ì§€ë°ì´í„°/ì¤‘ì•™ì„ ì¹¨ë²”/ì¤‘ì•™ì„ ì£¼í™©ìƒ‰ì‹¤ì„ ìœ„ë°˜/20230227_ì¤‘ì•™ì„ ì£¼í™©ìƒ‰ì‹¤ì„ ìœ„ë°˜_0000000497/"

path_ = path
fig = plt.figure(figsize=(10,10)) # rows*cols í–‰ë ¬ì˜ ië²ˆì§¸ subplot ìƒì„±
rows = 5
cols = 5
i = 1
 
xlabels = [f"{x}" if x!=0 else 'xlabel' for x in range(26) ]


for filename in sorted(os.listdir(path_))[:25]:
    filename = os.path.join(path_, filename)
    img = cv2.imread(filename)
    
    ax = fig.add_subplot(rows, cols, i)
    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax.set_xlabel(xlabels[i])
    ax.set_xticks([]), ax.set_yticks([])
    i += 1

plt.show()
classifier(path)


# In[51]:
# In[52]:

# # ======ì§„ë¡œë³€ê²½ìœ„ë°˜======

# In[53]:
# In[54]:
# In[55]:
path = "/mnt/traffic/êµí†µë°ì´í„°/test_ì´ë¯¸ì§€ë°ì´í„°/ì§„ë¡œë³€ê²½ìœ„ë°˜/ì¼ë°˜ë„ë¡œì§„ë¡œë³€ê²½ìœ„ë°˜/20230227_ì¼ë°˜ë„ë¡œì§„ë¡œë³€ê²½ìœ„ë°˜_0000000496/"
path_ = path
fig = plt.figure(figsize=(10,10)) # rows*cols í–‰ë ¬ì˜ ië²ˆì§¸ subplot ìƒì„±
rows = 5
cols = 5
i = 1
 
xlabels = [f"{x}" if x!=0 else 'xlabel' for x in range(26) ]

for filename in sorted(os.listdir(path_))[:25]:
    filename = os.path.join(path_, filename)
    img = cv2.imread(filename)
    
    ax = fig.add_subplot(rows, cols, i)
    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax.set_xlabel(xlabels[i])
    ax.set_xticks([]), ax.set_yticks([])
    i += 1

plt.show()
classifier(path)
