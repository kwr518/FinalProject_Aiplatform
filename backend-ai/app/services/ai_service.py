import os
import cv2
import numpy as np
import tensorflow as tf
import requests
import urllib.parse
from datetime import datetime
from ultralytics import YOLO 
from app.core.config import (
    MODEL_PATH, YOLO_PATH, SEQUENCE_LENGTH, STEP_SIZE, 
    CATEGORIES, CSV_FILE, TEMP_VIDEO_DIR,
    USE_JAVA_SYNC, JAVA_SERVER_URL
)
from app.core.global_state import detection_logs
from app.services.s3_service import s3_manager

# ë²ˆí˜¸íŒ ì¸ì‹ ëª¨ë“ˆ
try:
    from .plate_ocr import PlateRecognizerModule
except ImportError:
    PlateRecognizerModule = None

# í•™ìŠµì‹œí‚¨ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
base_dir = os.path.dirname(os.path.dirname(__file__))
NEW_YOLO_PATH = os.path.join(base_dir, "models", "best.pt") 

processing_files = set()

class AIService:
    def __init__(self):
        print("â³ TF ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = tf.keras.models.load_model(MODEL_PATH, compile=False)
        
        print(f"â³ YOLO í•™ìŠµ ëª¨ë¸ ë¡œë”© ì¤‘: {NEW_YOLO_PATH}")
        try:
            self.obj_detector = YOLO(NEW_YOLO_PATH)
            print("âœ… YOLO ê°ì²´ íƒì§€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ YOLO ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.obj_detector = None

        try:
            self.lpr_system = PlateRecognizerModule(YOLO_PATH)
        except:
            self.lpr_system = None

    def analyze_local_video(self, local_path):
        """ìë°” ì„œë²„ì—ì„œ ì „ë‹¬ë°›ì€ ë¡œì»¬ íŒŒì¼ì„ ì§ì ‘ ë¶„ì„í•˜ëŠ” ë©”ì„œë“œ"""
        try:
            filename = os.path.basename(local_path)
            cap = cv2.VideoCapture(local_path)
            all_frames = []
            detected_items = set() 

            print(f"ğŸ”„ AI ë¶„ì„ ì—”ì§„ ê°€ë™ (YOLO + TF): {filename}")

            while True:
                ret, frame = cap.read()
                if not ret: break

                # 1. YOLO(.pt) ì‹¤ì‹œê°„ íƒì§€
                if self.obj_detector:
                    results = self.obj_detector(frame, conf=0.4, verbose=False)
                    for box in results[0].boxes:
                        name = self.obj_detector.names[int(box.cls[0])]
                        detected_items.add(name)

                # í”„ë ˆì„ ì „ì²˜ë¦¬ (TF ëª¨ë¸ìš©)
                all_frames.append(cv2.resize(frame, (128, 128)) / 255.0)
            
            cap.release()

            # 2. ìœ„ë°˜ íŒë‹¨ (TensorFlow)
            if len(all_frames) < SEQUENCE_LENGTH:
                return {"result": "ë¶„ì„ ë¶ˆê°€(ì˜ìƒ ì§§ìŒ)", "prob": 0, "plate": "-"}

            windows = [all_frames[i : i + SEQUENCE_LENGTH] for i in range(0, len(all_frames) - SEQUENCE_LENGTH + 1, STEP_SIZE)]
            predictions = self.model.predict(np.array(windows), batch_size=2, verbose=0)
            
            best_prob, best_class_idx, best_window_idx = 0, -1, -1
            for i, pred in enumerate(predictions):
                idx = np.argmax(pred)
                if pred[idx] > best_prob:
                    best_prob, best_class_idx, best_window_idx = pred[idx], idx, i

            # =========================================================
            # ğŸš€ [í•µì‹¬ ìˆ˜ì •] ì •ìƒ ì£¼í–‰ í•„í„°ë§ (ì„ê³„ê°’ ì ìš©)
            # =========================================================
            MIN_CONFIDENCE = 0.75  # 75% ë¯¸ë§Œì´ë©´ ìœ„ë°˜ ì•„ë‹˜(ì •ìƒ)ìœ¼ë¡œ ê°„ì£¼

            if best_prob < MIN_CONFIDENCE:
                raw_label = "ì •ìƒ ì£¼í–‰"
                # ì •ìƒ ì£¼í–‰ì´ë©´ ë²ˆí˜¸íŒ ì¸ì‹ êµ³ì´ í•  í•„ìš” ì—†ìœ¼ë‹ˆ idx ì´ˆê¸°í™” (ì„ íƒì‚¬í•­)
                best_window_idx = -1 
            else:
                # 75% ì´ìƒì¼ ë•Œë§Œ ìœ„ë°˜ìœ¼ë¡œ ì¸ì •
                raw_label = CATEGORIES[best_class_idx] if best_class_idx != -1 else "ì •ìƒ ì£¼í–‰"

            # YOLO ê°ì§€ ê²°ê³¼ ìš”ì•½
            obj_summary = ", ".join(list(detected_items)) if detected_items else "ì—†ìŒ"
            
            final_display_result = f"{raw_label} ({obj_summary})"

            # 3. ë²ˆí˜¸íŒ ì¸ì‹ (ìœ„ë°˜ì¼ ë•Œë§Œ ìˆ˜í–‰í•˜ê±°ë‚˜, ì •ìƒì´ì–´ë„ ìˆ˜í–‰ ê°€ëŠ¥)
            plate_text = "ì¸ì‹ ë¶ˆê°€"
            # best_window_idxê°€ -1ì´ ì•„ë‹ˆë¼ëŠ” ê±´ ìœ„ë°˜ì´ ê°ì§€ë˜ì—ˆë‹¤ëŠ” ëœ»
            if self.lpr_system and best_window_idx != -1:
                plate_text = self.lpr_system.process_segment(local_path, best_window_idx * STEP_SIZE, SEQUENCE_LENGTH) or "ì¸ì‹ ë¶ˆê°€"
            elif raw_label == "ì •ìƒ ì£¼í–‰":
                plate_text = "-"  # ì •ìƒ ì£¼í–‰ì´ë©´ ë²ˆí˜¸íŒ êµ³ì´ ì•ˆ ë„ì›€

            return {
                "result": final_display_result, 
                "plate": plate_text,
                "location": "ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬ ë§¤ì‚°ë¡œ 1",
                "time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "prob": round(float(best_prob * 100), 2),
                "info": f"YOLO ê°ì§€: {obj_summary}",
                "video_url": "" 
            }

        except Exception as e:
            print(f"âŒ ë¡œì»¬ ë¶„ì„ ì—ëŸ¬: {e}")
            return {"result": "ì—ëŸ¬ ë°œìƒ", "prob": 0, "plate": "Error"}

    def process_video_task(self, video_key):
        # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
        decoded_key = urllib.parse.unquote_plus(video_key)
        filename = os.path.basename(decoded_key)

        if filename in processing_files: return
        processing_files.add(filename)

        try:
            local_path = os.path.join(TEMP_VIDEO_DIR, filename)
            s3_manager.download_file(decoded_key, local_path)
            
            payload = self.analyze_local_video(local_path)
            payload["video_url"] = s3_manager.get_presigned_url(decoded_key)
            
            detection_logs.append(payload)

            if USE_JAVA_SYNC:
                requests.post(JAVA_SERVER_URL, json=payload, timeout=3)
            
            print(f"âœ… ë¶„ì„ ì™„ë£Œ: {payload['result']}")

            if os.path.exists(local_path): os.remove(local_path)
            processing_files.remove(filename)

        except Exception as e:
            print(f"âŒ ë¶„ì„ ì—ëŸ¬: {e}")
            if filename in processing_files: processing_files.remove(filename)

ai_manager = AIService()